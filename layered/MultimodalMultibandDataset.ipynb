{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6e58dd-c583-46f1-8373-5e15da909b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/lightning/fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "/usr/local/lib/python3.10/site-packages/pkg_resources/__init__.py:3142: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ligo')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/usr/local/lib/python3.10/site-packages/pkg_resources/__init__.py:3142: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/usr/local/lib/python3.10/site-packages/pkg_resources/__init__.py:3142: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('zope')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/usr/local/lib/python3.10/site-packages/lightning/fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning.fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/usr/local/lib/python3.10/site-packages/pkg_resources/__init__.py:2554: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/usr/local/lib/python3.10/site-packages/lightning/pytorch/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('lightning.pytorch')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/usr/local/lib/python3.10/site-packages/pkg_resources/__init__.py:2554: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/usr/local/lib/python3.10/site-packages/lalsimulation/lalsimulation.py:8: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal\n",
      "PyCBC.libutils: pkg-config call failed, setting NO_PKGCONFIG=1\n",
      "/usr/local/lib/python3.10/site-packages/ligo/lw/ligolw.py:426: DeprecationWarning: invalid escape sequence '\\Z'\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/waveform/nltides.py:8: DeprecationWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"Calculate the change to the Fourier phase change due\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/waveform/bank.py:210: DeprecationWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"Class to provide some basic helper functions and information\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/calc_moments.py:329: DeprecationWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/coord_utils.py:584: DeprecationWarning: invalid escape sequence '\\c'\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/coord_utils.py:606: DeprecationWarning: invalid escape sequence '\\c'\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/coord_utils.py:624: DeprecationWarning: invalid escape sequence '\\c'\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/option_utils.py:177: DeprecationWarning: invalid escape sequence '\\i'\n",
      "  \"space metric:  integrals of the form \\int F(f) df \"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/tmpltbank/option_utils.py:178: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  \"are approximated as \\sum F(f) delta_f.  REQUIRED. \"\n",
      "/usr/local/lib/python3.10/site-packages/pycbc/results/str_utils.py:95: DeprecationWarning: invalid escape sequence '\\%'\n",
      "  \"\"\"Given a numerical value and some bound on it, formats the number into a\n",
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train.data.supervised import MultimodalMultibandDataset\n",
    "from ml4gw.distributions import PowerLaw\n",
    "import torch\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "from train.callbacks import MultimodalMultibandModelCheckpoint, MultimodalMultibandSaveAugmentedBatch\n",
    "from train.model import MultimodalMultibandModule\n",
    "from architectures.stackedresnets import MultimodalMultiband\n",
    "from ml4gw.nn.norm import GroupNorm1DGetter\n",
    "from train.metrics import TimeSlideAUROC\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(0)\n",
    "plt.close()\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import sys\n",
    "sys.path.append('/home/seiya.tsukamoto/aframe/libs/priors/')\n",
    "from priors.priors import end_o3_ratesandpops\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from torchmetrics.classification import BinaryAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245a0625-0443-4bb4-b54c-029b43c79630",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = MultimodalMultiband(classes = [64, 64, 64, 64], num_ifos = 2, layers = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], \n",
    "                           norm_layer = GroupNorm1DGetter(groups = 16), sample_rate = 2048, kernel_length = 2.75)\n",
    "metric = TimeSlideAUROC(max_fpr = 1e-3, pool_length = 8, stride = 0.5)\n",
    "weight_decay = 0.0\n",
    "learning_rate = 0.000585\n",
    "pct_lr_ramp = 0.115\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "batches_per_epoch = 1\n",
    "num_files_per_batch = 10\n",
    "chunk_size = 10000\n",
    "chunks_per_epoch = 10\n",
    "psd_length = 8\n",
    "fftlength = None\n",
    "\n",
    "waveform_prob = 0.277\n",
    "swap_prob = 0.014\n",
    "mute_prob = 0.055\n",
    "left_pad = 0.25\n",
    "right_pad = 0.05\n",
    "snr_sampler = PowerLaw(minimum = 4, maximum = 100, index = -3)\n",
    "valid_frac = 0.01\n",
    "valid_stride = 0.5\n",
    "num_valid_views = 2\n",
    "valid_livetime = 1000\n",
    "\n",
    "\n",
    "\n",
    "logger = CSVLogger(save_dir = '/home/seiya.tsukamoto/aframe/test', flush_logs_every_n_steps = 10)\n",
    "callbacks = [MultimodalMultibandModelCheckpoint(monitor = \"valid_auroc\", mode = \"max\", save_top_k = 1, save_last = True, auto_insert_metric_name = False),\n",
    "             MultimodalMultibandSaveAugmentedBatch()]\n",
    "max_epochs = 1\n",
    "check_val_every_n_epoch = 1\n",
    "log_every_n_steps = 20\n",
    "\n",
    "\n",
    "\n",
    "ifos = [\"H1\", \"L1\"]\n",
    "train_start = 1240579783\n",
    "train_stop = 1241443783\n",
    "test_stop = 1244035783 \n",
    "max_duration = 1000\n",
    "Tb = 31536000\n",
    "shifts = [0, 1]\n",
    "seed = 1122\n",
    "\n",
    "streams_per_gpu = 6\n",
    "\n",
    "kernel_length = 2.75\n",
    "prior = end_o3_ratesandpops\n",
    "\n",
    "fftlength = None \n",
    "sample_rate = 2048\n",
    "fduration = 1\n",
    "highpass = 32\n",
    "lowpass = 1024\n",
    "\n",
    "inference_psd_length = 64\n",
    "inference_sampling_rate = 4\n",
    "inference_batch_size = 128\n",
    "\n",
    "waveform_duration = 10\n",
    "coalescence_time = 8\n",
    "min_valid_duration = 10\n",
    "\n",
    "data_dir = '/home/seiya.tsukamoto/aframe/layered/data/train'\n",
    "\n",
    "resample_rates = [2048, 1024, 512]\n",
    "high_passes = [32, 32, 32]\n",
    "low_passes = [1024, 128, 64]\n",
    "kernel_lengths = [0.5, 1, 2]\n",
    "fft_kernel_length = 1\n",
    "fft_high_pass = 32\n",
    "fft_low_pass = 1024\n",
    "inference_sampling_rates = [8, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8753c1-3b7a-4e20-bebd-6fbb3c4cbe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 13:37:27,704 - root - INFO - Downloading data to /home/seiya.tsukamoto/aframe/layered/data/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "module = MultimodalMultibandModule(arch = arch, metric = metric, learning_rate = learning_rate, \n",
    "                          pct_lr_ramp = pct_lr_ramp, weight_decay = weight_decay, verbose = True)\n",
    "MMD = MultimodalMultibandDataset(data_dir = data_dir, ifos = ifos, sample_rate = sample_rate,\n",
    "                                   valid_frac = valid_frac, batches_per_epoch = batches_per_epoch, \n",
    "                                   num_files_per_batch = num_files_per_batch, batch_size = batch_size,\n",
    "                                   kernel_length = kernel_length, fduration = fduration, psd_length = psd_length, \n",
    "                                   waveform_prob = waveform_prob, max_snr = None, snr_alpha = None,\n",
    "                                   left_pad = left_pad, right_pad = right_pad, fftlength = fftlength,\n",
    "                                   highpass = highpass, lowpass = lowpass, snr_sampler = snr_sampler, \n",
    "                                   valid_stride = valid_stride, num_valid_views = num_valid_views, \n",
    "                                   min_valid_duration = min_valid_duration, valid_livetime = valid_livetime, \n",
    "                                   verbose = True, chunks_per_epoch = chunks_per_epoch,chunk_size = chunk_size,\n",
    "                                   resample_rates = resample_rates, kernel_lengths = kernel_lengths, \n",
    "                                   high_passes = high_passes, low_passes = low_passes, \n",
    "                                   fft_kernel_length = fft_kernel_length, fft_high_pass = fft_high_pass, \n",
    "                                   fft_low_pass = fft_low_pass, inference_sampling_rates = inference_sampling_rates)\n",
    "trainer = Trainer(accelerator = 'cpu', strategy = 'ddp_notebook', devices = 1, num_nodes = 1, logger = logger, \n",
    "                  callbacks = callbacks, max_epochs = 1, check_val_every_n_epoch = 1, log_every_n_steps = 20, \n",
    "                  benchmark = True, fast_dev_run = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcbb626-3801-4913-9943-8668ac3ce898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 13:37:30,566 - AframeDataset - INFO - Validated sample rate 2048.0\n",
      "2025-09-09 13:37:30,570 - AframeDataset - INFO - Constructing sample rate dependent transforms\n",
      "2025-09-09 13:37:30,668 - AframeDataset - INFO - Loading validation background data\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "2025-09-09 13:37:31,422 - AframeDataset - INFO - Constructing validation timeslides from background segments /home/seiya.tsukamoto/aframe/layered/data/train/background/background-1241437182-6601.hdf5\n",
      "2025-09-09 13:37:31,454 - h5py._conv - DEBUG - Creating converter from 3 to 5\n",
      "2025-09-09 13:38:09,644 - AframeDataset - INFO - Validating on 20000 waveforms\n",
      "2025-09-09 13:38:09,649 - AframeDataset - INFO - Loading 20000 validation signals\n",
      "2025-09-09 13:38:11,073 - AframeDataset - INFO - Initial dataloading complete\n",
      "2025-09-09 13:38:11,501 - AframeModel - INFO - Scaled lr by 1 to 0.000585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 13:38:11,605 - AframeDataset - DEBUG - Using 6 workers for strain data loading\n",
      "2025-09-09 13:38:11,689 - AframeDataset - INFO - Training on pool of 100000 waveforms. Sampling 1 batches per chunk from 10 chunks of size 10000 each epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "  | Name   | Type                | Params\n",
      "-----------------------------------------------\n",
      "0 | model  | MultimodalMultiband | 6.0 M \n",
      "1 | metric | TimeSlideAUROC      | 0     \n",
      "-----------------------------------------------\n",
      "6.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 M     Total params\n",
      "23.848    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 13:38:17,927 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:38:17,945 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "Epoch 0: 100%|███████████████████████████████████████████| 1/1 [01:17<00:00,  0.01it/s, v_num=23, train_loss_step=0.603]\n",
      "Validation: |                                                                                     | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|██▉                                                        | 1/20 [00:12<03:58,  0.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█████▉                                                     | 2/20 [00:31<04:39,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|████████▊                                                  | 3/20 [00:49<04:39,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███████████▊                                               | 4/20 [01:07<04:31,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 5/20 [01:26<04:18,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████████████████▋                                         | 6/20 [01:43<04:01,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████████████████████▋                                      | 7/20 [02:01<03:44,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████▌                                   | 8/20 [02:18<03:28,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|██████████████████████████▌                                | 9/20 [02:36<03:11,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████                             | 10/20 [02:48<02:48,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████████████████████████████▉                          | 11/20 [02:51<02:20,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████████████████████████████▊                       | 12/20 [03:08<02:05,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|█████████████████████████████████████▋                    | 13/20 [03:25<01:50,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████████████████████████████████▌                 | 14/20 [03:43<01:35,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████████████████████████████████████▌              | 15/20 [03:54<01:18,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████▍           | 16/20 [04:12<01:03,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████████████████████████████████████████▎        | 17/20 [04:30<00:47,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████████████████████████████████████████▏     | 18/20 [04:48<00:32,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████████████████████████████████████████████   | 19/20 [05:05<00:16,  0.06it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 20/20 [05:24<00:00,  0.06it/s]\u001b[A2025-09-09 13:46:25,403 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:46:25,422 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:46:25,437 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/metrics.csv\n",
      "\n",
      "Epoch 0: 100%|███████████████████████████████████████████| 1/1 [06:49<00:00,  0.00it/s, v_num=23, train_loss_step=0.603]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████| 1/1 [06:49<00:00,  0.00it/s, v_num=23, train_loss_step=0.603, train_loss_epoch=0.603]2025-09-09 13:46:25,776 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/checkpoints/0-1.ckpt\n",
      "2025-09-09 13:46:26,052 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/checkpoints/last.ckpt\n",
      "2025-09-09 13:46:26,211 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:46:26,225 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:46:26,238 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/metrics.csv\n",
      "2025-09-09 13:46:26,242 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/metrics.csv\n",
      "2025-09-09 13:46:26,246 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████| 1/1 [06:49<00:00,  0.00it/s, v_num=23, train_loss_step=0.603, train_loss_epoch=0.603]\n",
      "2025-09-09 13:46:26,377 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/checkpoints/0-1.ckpt\n",
      "2025-09-09 13:47:37,782 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:47:37,879 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_23/hparams.yaml\n",
      "2025-09-09 13:47:37,994 - fsspec.local - DEBUG - open file: /tmp/tmp2q3l0zyx/.temp.ckpt\n",
      "2025-09-09 13:47:39,485 - fsspec.local - DEBUG - open file: /tmp/tmp2q3l0zyx/.temp.ckpt\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, datamodule=MMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc6dcbf-a8fe-470d-bb98-c3dceab8d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 01:48:40,903 - AframeDataset - INFO - Validated sample rate 2048.0\n",
      "2025-09-09 01:48:40,904 - AframeDataset - INFO - Constructing sample rate dependent transforms\n",
      "2025-09-09 01:48:41,090 - AframeDataset - INFO - Loading validation background data\n",
      "2025-09-09 01:48:41,906 - AframeDataset - INFO - Constructing validation timeslides from background segments /home/seiya.tsukamoto/aframe/layered/data/train/background/background-1241437182-6601.hdf5\n",
      "2025-09-09 01:48:41,956 - h5py._conv - DEBUG - Creating converter from 3 to 5\n",
      "2025-09-09 01:49:27,866 - AframeDataset - INFO - Validating on 20000 waveforms\n",
      "2025-09-09 01:49:27,871 - AframeDataset - INFO - Loading 20000 validation signals\n",
      "2025-09-09 01:49:29,073 - AframeDataset - INFO - Initial dataloading complete\n"
     ]
    }
   ],
   "source": [
    "trainer.strategy._lightning_module = module\n",
    "MMD.trainer = trainer\n",
    "MMD.prepare_data()\n",
    "MMD.setup(stage = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8998dd4-c16e-4b77-b533-a5af1939560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 02:57:28,882 - fsspec.local - DEBUG - open file: /home/seiya.tsukamoto/aframe/test/lightning_logs/version_18/checkpoints/0-1.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMultibandModule(\n",
       "  (model): MultimodalMultiband(\n",
       "    (resnets): ModuleList(\n",
       "      (0-2): 3 x ResNet1D(\n",
       "        (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "        (bn1): GroupNorm1D()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (residual_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "                (1): GroupNorm1D()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
       "                (1): GroupNorm1D()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): ResNet1D(\n",
       "        (conv1): Conv1d(6, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "        (bn1): GroupNorm1D()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (residual_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "                (1): GroupNorm1D()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
       "                (1): GroupNorm1D()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "            (2): BasicBlock(\n",
       "              (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn1): GroupNorm1D()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "              (bn2): GroupNorm1D()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (metric): TimeSlideAUROC(\n",
       "    (metric): BinaryAUROC()\n",
       "    (pool): MaxPool1d(kernel_size=16, stride=8, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.serialization.add_safe_globals([ml4gw.distributions.PowerLaw])\n",
    "torch.serialization.add_safe_globals([torch.distributions.transforms.AffineTransform])\n",
    "torch.serialization.add_safe_globals([torch.distributions.transforms.PowerTransform])\n",
    "torch.serialization.add_safe_globals([torch.distributions.uniform.Uniform])\n",
    "module.__class__.load_from_checkpoint(\n",
    "    '/home/seiya.tsukamoto/aframe/test/lightning_logs/version_18/checkpoints/0-1.ckpt', arch=module.model, \n",
    "    metric=module.metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4342be64-19c9-4144-b349-e4005d6ee98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 01:49:29,338 - AframeDataset - DEBUG - Using 6 workers for strain data loading\n",
      "2025-09-09 01:49:29,797 - AframeDataset - INFO - Training on pool of 100000 waveforms. Sampling 2 batches per chunk from 10 chunks of size 10000 each epoch\n"
     ]
    }
   ],
   "source": [
    "MMD.trainer.training = True\n",
    "MMD.trainer.validating = False\n",
    "ds = MMD.train_dataloader()\n",
    "for train_batch in ds:\n",
    "    train_batch = MMD.on_before_batch_transfer(train_batch, 10)\n",
    "    train_batch = MMD.on_after_batch_transfer(train_batch, 10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ba27bd-10a2-43c2-872a-fcf65f5d8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2e973d-6626-4f4a-8344-95e0d733d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 6, 993])\n"
     ]
    }
   ],
   "source": [
    "for batch in X:\n",
    "    print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51dddfb1-5ba7-44e4-b85b-7299b39b10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD.trainer.training = False\n",
    "MMD.trainer.validating = True\n",
    "ds = MMD.val_dataloader()\n",
    "for val_batch in ds:\n",
    "    val_batch = MMD.on_before_batch_transfer(val_batch, 10)\n",
    "    val_batch = MMD.on_after_batch_transfer(val_batch, 10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c7a0ef-5e47-4d50-a9b7-f88abffc0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift, X_bg, X_fg = val_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d183cd-e8cb-4725-a4a8-8b8be4cff7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 2, 1024])\n",
      "torch.Size([100, 6, 993])\n",
      "torch.Size([5, 100, 2, 1024])\n",
      "torch.Size([5, 100, 2, 1024])\n",
      "torch.Size([5, 100, 2, 1024])\n",
      "torch.Size([5, 100, 6, 993])\n"
     ]
    }
   ],
   "source": [
    "for batch in X_bg:\n",
    "    print(batch.size())\n",
    "\n",
    "for batch in X_fg:\n",
    "    print(batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb15d33-3341-4107-ad5f-e9a3e3fa61d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c43dd-b0de-465d-ae8c-4f7d3a7ab667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
